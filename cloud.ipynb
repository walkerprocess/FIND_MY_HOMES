{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "# 🔑 .env 로드\n",
    "load_dotenv()\n",
    "embedding_api_key = os.getenv(\"Embedding_API_KEY\")\n",
    "embedding_endpoint = os.getenv(\"Embedding_ENDPOINT\")\n",
    "gpt_api_key = os.getenv('OPENAI_API_KEY')\n",
    "gpt_endpoint = os.getenv('OPENAI_ENDPOINT')\n",
    "BLOB_CONN_STR = os.getenv('BLOB_CONN_STR')\n",
    "DI_ENDPOINT = os.getenv('DI_ENDPOINT')\n",
    "DI_API_KEY = os.getenv('DI_API_KEY')\n",
    "\n",
    "# 📁 경로 설정\n",
    "BLOB_CONTAINER_NAME = \"pdf-container\"\n",
    "PDF_FOLDER = r\"E:\\work\\MS_project_2\\code\\테이블처리o\\data\\pdfs/d\"\n",
    "MD_FOLDER = r\"E:\\work\\MS_project_2\\code\\테이블처리o\\data\\markdowns\"\n",
    "os.makedirs(MD_FOLDER, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 클라이언트 초기화\n",
    "blob_service = BlobServiceClient.from_connection_string(BLOB_CONN_STR)\n",
    "container_client = blob_service.get_container_client(BLOB_CONTAINER_NAME)\n",
    "if not container_client.exists():\n",
    "    container_client.create_container()\n",
    "\n",
    "di_client = DocumentIntelligenceClient(endpoint=DI_ENDPOINT, credential=AzureKeyCredential(DI_API_KEY))\n",
    "\n",
    "\n",
    "def upload_pdf_to_blob(pdf_path: str, blob_name: str) -> str:\n",
    "    \"\"\"PDF를 Blob에 업로드하고 SAS URL 반환\"\"\"\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        blob_client.upload_blob(f, overwrite=True)\n",
    "\n",
    "    sas_token = generate_blob_sas(\n",
    "        account_name=blob_service.account_name,\n",
    "        container_name=BLOB_CONTAINER_NAME,\n",
    "        blob_name=blob_name,\n",
    "        account_key=blob_service.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=datetime.utcnow() + timedelta(minutes=15)\n",
    "    )\n",
    "\n",
    "    return f\"{blob_client.url}?{sas_token}\"\n",
    "\n",
    "\n",
    "def analyze_pdf_to_markdown(sas_url: str) -> str:\n",
    "    \"\"\"Document Intelligence를 사용해 Markdown으로 변환\"\"\"\n",
    "    poller = di_client.begin_analyze_document(\n",
    "        model_id=\"prebuilt-layout\",\n",
    "        body=AnalyzeDocumentRequest(url_source=sas_url),\n",
    "        output_content_format='markdown'\n",
    "    )\n",
    "    result = poller.result()\n",
    "    return result.content\n",
    "\n",
    "\n",
    "def request_gpt(prompt: str) -> str:\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'api-key': gpt_api_key\n",
    "    }\n",
    "    body = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    '너는 HTML 테이블을 사람이 이해할 수 있도록 자연어 문장으로 변환해.  '\n",
    "                    '항목과 값을 \"구분: 내용\" 식으로 나누지 말고, 원래 테이블에서 쓰인 항목명을 그대로 key로 사용해.  '\n",
    "                    '예: \"임대조건 : 내용\", \"임대보증금-월임대료 전환 : 내용\"처럼.  '\n",
    "                    '항목이 반복되는 경우에는 구분자를 붙여서 명확하게 구분해줘.  '\n",
    "                    '불필요한 요약이나 도입부 없이 표의 핵심 내용만 변환해줘.'\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800\n",
    "    }\n",
    "\n",
    "    response = requests.post(gpt_endpoint, headers=headers, json=body)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    else:\n",
    "        print(\"❌ 요청 실패:\", response.status_code, response.text)\n",
    "        return \"⚠️ 오류가 발생했습니다.\"\n",
    "\n",
    "\n",
    "def convert_md_tables_with_llm_parallel(md_text: str, max_workers=5) -> str:\n",
    "    soup = BeautifulSoup(md_text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    table_strs = [str(table) for table in tables]\n",
    "    unique_tables = list(set(table_strs))\n",
    "    table_to_text = {}\n",
    "\n",
    "    def process_table(table_html):\n",
    "        prompt = (\n",
    "            f\"다음 HTML 테이블의 내용을 자연어 문장으로 간결하게 변환해줘.\\n\\n{table_html}\"\n",
    "        )\n",
    "        result = request_gpt(prompt)\n",
    "        return table_html, result\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_table, tbl) for tbl in unique_tables]\n",
    "        for future in as_completed(futures):\n",
    "            tbl_html, gpt_result = future.result()\n",
    "            table_to_text[tbl_html] = gpt_result\n",
    "\n",
    "    for original_table in table_strs:\n",
    "        if original_table in table_to_text:\n",
    "            md_text = md_text.replace(original_table, table_to_text[original_table])\n",
    "\n",
    "    return md_text\n",
    "\n",
    "\n",
    "def preprocess_markdown_headers(md_text: str) -> str:\n",
    "    md_text = re.sub(r'^(#{1,6}\\s*■?\\s*[^:\\n]+):\\s*(.+)$', r'\\1\\n\\2', md_text, flags=re.MULTILINE)\n",
    "    md_text = re.sub(r'^(■\\s*\\([^)]+\\))\\s+(.+)$', r'\\1\\n\\2', md_text, flags=re.MULTILINE)\n",
    "    return md_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 처리할 PDF 파일 수: 2\n",
      "\n",
      "📄 처리 중: 서울지역본부 청년 매입임대주택\n",
      "✅ Blob 업로드 및 SAS URL 완료\n",
      "✅ Document Intelligence 분석 완료\n",
      "✅ GPT 테이블 변환 완료\n",
      "✅ 저장 완료: E:\\work\\MS_project_2\\code\\테이블처리o\\data\\markdowns\\서울지역본부 청년 매입임대주택.md\n",
      "\n",
      "📄 처리 중: 아츠스테이영등포_입주자모집공고문\n",
      "✅ Blob 업로드 및 SAS URL 완료\n",
      "✅ Document Intelligence 분석 완료\n",
      "✅ GPT 테이블 변환 완료\n",
      "✅ 저장 완료: E:\\work\\MS_project_2\\code\\테이블처리o\\data\\markdowns\\아츠스테이영등포_입주자모집공고문.md\n"
     ]
    }
   ],
   "source": [
    "# ✅ 전체 처리 루프\n",
    "pdf_files = glob(os.path.join(PDF_FOLDER, \"*.pdf\"))\n",
    "print(f\"🔍 처리할 PDF 파일 수: {len(pdf_files)}\")\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    blob_name = f\"{filename}.pdf\"\n",
    "    md_path = os.path.join(MD_FOLDER, f\"{filename}.md\")\n",
    "\n",
    "    print(f\"\\n📄 처리 중: {filename}\")\n",
    "\n",
    "    # 1. 업로드 및 SAS URL 생성\n",
    "    sas_url = upload_pdf_to_blob(pdf_path, blob_name)\n",
    "    print(\"✅ Blob 업로드 및 SAS URL 완료\")\n",
    "\n",
    "    # 2. Markdown 변환\n",
    "    md_content = analyze_pdf_to_markdown(sas_url)\n",
    "    print(\"✅ Document Intelligence 분석 완료\")\n",
    "\n",
    "    # 3. GPT 테이블 변환\n",
    "    md_with_tables = convert_md_tables_with_llm_parallel(md_content)\n",
    "    print(\"✅ GPT 테이블 변환 완료\")\n",
    "\n",
    "    # 4. 헤더 전처리\n",
    "    final_md = preprocess_markdown_headers(md_with_tables)\n",
    "\n",
    "    # 5. 저장\n",
    "    with open(md_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(final_md)\n",
    "    print(f\"✅ 저장 완료: {md_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 총 Markdown 파일 수: 8\n",
      "\n",
      "🚀 처리 중: (대전충남)25년1차청년매입임대_표준입주자모집공고문\n",
      "\n",
      "🚀 처리 중: (정정공고문)25년1차청년매입임대_표준입주자모집공고문\n",
      "\n",
      "🚀 처리 중: 2025년 1차 대구경북 청년매입임대 입주자 모집 공고문\n",
      "\n",
      "🚀 처리 중: 2025년1차청년매입임대입주자모집공고문(광주전남)\n",
      "\n",
      "🚀 처리 중: 25년 1차 청년매입임대 입주자 모집 공고문(강원지역본부)\n",
      "\n",
      "🚀 처리 중: 25년1차청년매입임대입주자모집공고문\n",
      "\n",
      "🚀 처리 중: 서울지역본부 청년 매입임대주택\n",
      "\n",
      "🚀 처리 중: 아츠스테이영등포_입주자모집공고문\n",
      "\n",
      "✅ 전체 청크 수: 835\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 📁 마크다운 폴더 경로 (raw string으로 경로 작성)\n",
    "MARKDOWN_FOLDER = r\"E:\\work\\MS_project_2\\code\\테이블처리o\\data\\markdowns\"\n",
    "\n",
    "# ✅ 분할 도구 정의\n",
    "header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n",
    "    (\"#\", \"section\"),\n",
    "    (\"##\", \"subsection\"),\n",
    "    (\"###\", \"subsubsection\"),\n",
    "    (\"■\", \"bullet\"),\n",
    "    (\"※\", \"bullet\"),\n",
    "    (\"▪\", \"subbullet\"),\n",
    "    (\"✔\", \"check\")\n",
    "])\n",
    "\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# ✅ 전체 문서 리스트\n",
    "all_docs = []\n",
    "\n",
    "# ✅ 모든 .md 파일 가져오기\n",
    "md_files = glob(os.path.join(MARKDOWN_FOLDER, \"*.md\"))\n",
    "print(f\"📄 총 Markdown 파일 수: {len(md_files)}\")\n",
    "\n",
    "# ✅ 각 파일 처리\n",
    "for md_path in md_files:\n",
    "    filename = os.path.splitext(os.path.basename(md_path))[0]  # 확장자 없는 파일명\n",
    "\n",
    "    print(f\"\\n🚀 처리 중: {filename}\")\n",
    "\n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        md_text = f.read()\n",
    "\n",
    "    # 1. Markdown 헤더 기준 분할\n",
    "    header_docs = header_splitter.split_text(md_text)\n",
    "\n",
    "    # 2. 각 문서에 파일명 메타데이터 추가\n",
    "    for doc in header_docs:\n",
    "        doc.metadata[\"source\"] = filename\n",
    "\n",
    "    # 3. RecursiveCharacterTextSplitter로 chunk 분할\n",
    "    for doc in header_docs:\n",
    "        sub_docs = recursive_splitter.split_text(doc.page_content)\n",
    "\n",
    "        for chunk in sub_docs:\n",
    "            all_docs.append(\n",
    "                Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata=doc.metadata  # section, subsection, bullet, source 포함\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(f\"\\n✅ 전체 청크 수: {len(all_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bullet': '공동거주형임을 인지하지 못하고 신청한 후 계약을 포기하는 사례가 빈번하게 발생하고 있습니다.', 'section': '2 입주자격 및 입주자 선정기준', 'subsection': '■ 입주순위', 'source': '(대전충남)25년1차청년매입임대_표준입주자모집공고문'}\n",
      "=========================\n",
      "2순위는 본인과 부모의 월평균 소득이 전년도 도시근로자 가구원수별 가구당 월평균소득의 100% 이하이며, 본인과 부모의 자산이 국민임대주택 자산기준을 충족하는 자입니다.  \n",
      "3순위는 본인의 월평균 소득이 전년도 도시근로자 1인 가구 월평균소득 100% 이하이며, 행복주택(청년) 자산기준을 충족하는 자입니다.\n"
     ]
    }
   ],
   "source": [
    "print(all_docs[11].metadata)\n",
    "print('=========================')\n",
    "print(all_docs[11].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import AzureSearch\n",
    "embedding_api_version = \"2024-02-15-preview\"\n",
    "embedding_deployment = \"text-embedding-3-small\"\n",
    "os.environ.pop(\"OPENAI_API_BASE\", None)\n",
    "os.environ.pop(\"BASE_URL\", None)\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    api_key=embedding_api_key,\n",
    "    azure_endpoint=embedding_endpoint,\n",
    "    model=embedding_deployment,\n",
    "    openai_api_version=embedding_api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Azure AI Search 인덱스 생성 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 업로드 중: 100%|██████████| 835/835 [04:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 전체 문서 업로드 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SimpleField, SearchField, SearchFieldDataType,\n",
    "    VectorSearch, HnswAlgorithmConfiguration, VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile\n",
    ")\n",
    "\n",
    "# ✅ 1. API 키 및 엔드포인트\n",
    "#ai_search_index_name = \"new_index\"\n",
    "ai_search_index_name = \"add_new_index\"\n",
    "\n",
    "ai_search_endpoint = os.getenv('AI_Search_ENDPOINT')\n",
    "ai_search_api_key = os.getenv('AI_Search_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 2. 임베딩 설정\n",
    "embedding_deployment = \"text-embedding-3-small\"\n",
    "embedding_api_version = \"2024-02-15-preview\"\n",
    "\n",
    "os.environ.pop(\"OPENAI_API_BASE\", None)\n",
    "os.environ.pop(\"BASE_URL\", None)\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    api_key=embedding_api_key,\n",
    "    azure_endpoint=embedding_endpoint,\n",
    "    model=embedding_deployment,\n",
    "    openai_api_version=embedding_api_version\n",
    ")\n",
    "\n",
    "# ✅ 3. 인덱스 스키마 정의\n",
    "embedding_dim = 1536\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SearchField(name=\"source\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "    SearchField(name=\"section\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "    SearchField(name=\"subsection\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "    SearchField(name=\"subsubsection\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "    SearchField(name=\"bullet\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "    SearchField(name=\"subbullet\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "    SearchField(name=\"check\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "    SearchField(\n",
    "        name=\"embedding\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=embedding_dim,\n",
    "        vector_search_profile_name=\"default\"\n",
    "    )\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    profiles=[VectorSearchProfile(name=\"default\", algorithm_configuration_name=\"my-algorithm\")],\n",
    "    algorithms=[HnswAlgorithmConfiguration(name=\"my-algorithm\", kind=VectorSearchAlgorithmKind.HNSW)]\n",
    ")\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=ai_search_index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search\n",
    ")\n",
    "\n",
    "# ✅ 4. 인덱스 초기화 및 생성\n",
    "index_client = SearchIndexClient(endpoint=ai_search_endpoint, credential=AzureKeyCredential(ai_search_api_key))\n",
    "\n",
    "if ai_search_index_name in [i.name for i in index_client.list_indexes()]:\n",
    "    index_client.delete_index(ai_search_index_name)\n",
    "    print(\"🗑 기존 인덱스 삭제 완료\")\n",
    "\n",
    "index_client.create_index(index)\n",
    "print(\"✅ Azure AI Search 인덱스 생성 완료\")\n",
    "\n",
    "# ✅ 5. 벡터 데이터 업로드\n",
    "# 👉 여기서 all_docs는 이미 만들어진 Document 리스트라고 가정\n",
    "\n",
    "# 예: all_docs = [Document(page_content=..., metadata={...}), ...]\n",
    "\n",
    "search_client = SearchClient(endpoint=ai_search_endpoint, index_name=ai_search_index_name, credential=AzureKeyCredential(ai_search_api_key))\n",
    "\n",
    "batch = []\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "for doc in tqdm(all_docs, desc=\"📤 업로드 중\"):\n",
    "    vector = embedding.embed_query(doc.page_content)\n",
    "\n",
    "    record = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"content\": doc.page_content,\n",
    "        \"embedding\": vector,\n",
    "        \"source\": doc.metadata.get(\"source\", \"\"),\n",
    "        \"section\": doc.metadata.get(\"section\", \"\"),\n",
    "        \"subsection\": doc.metadata.get(\"subsection\", \"\"),\n",
    "        \"subsubsection\": doc.metadata.get(\"subsubsection\", \"\"),\n",
    "        \"bullet\": doc.metadata.get(\"bullet\", \"\"),\n",
    "        \"subbullet\": doc.metadata.get(\"subbullet\", \"\"),\n",
    "        \"check\": doc.metadata.get(\"check\", \"\")\n",
    "    }\n",
    "\n",
    "    batch.append(record)\n",
    "\n",
    "    if len(batch) >= BATCH_SIZE:\n",
    "        search_client.upload_documents(documents=batch)\n",
    "        batch = []\n",
    "\n",
    "# 남은 데이터 업로드\n",
    "if batch:\n",
    "    search_client.upload_documents(documents=batch)\n",
    "\n",
    "print(\"✅ 전체 문서 업로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
