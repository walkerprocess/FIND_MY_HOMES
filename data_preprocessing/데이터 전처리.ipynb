{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1830bdab",
   "metadata": {},
   "source": [
    "## PyMuPDF4LLM .md 전처리\n",
    "- 공백 테이블 병합\n",
    "- 병합셀 채워넣기\n",
    "- 현재: 해당 테이블이 위치하는 페이지 리스트를 입력하여 병합된 표(df)를 얻음\n",
    "- 주의: 컬럼을 잘못 읽어온 경우 예외처리, 한 페이지에 여러 표가 있는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d767571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "# PDF data 추출\n",
    "llama_reader = pymupdf4llm.LlamaMarkdownReader()\n",
    "llama_docs = llama_reader.load_data(r\"data\\pdf_data\\LH-25년1차청년매입임대입주자모집공고문(서울지역본부).pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ce9cb",
   "metadata": {},
   "source": [
    "### 1) 컬럼 예외처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4172b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO\n",
    "import re\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "special_chars = ['•', '■', '※']\n",
    "\n",
    "def fix_invalid_column_lines(md_text: str) -> str:\n",
    "    lines = md_text.splitlines()\n",
    "    new_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        # 조건: | 2개 이상 + 특수기호 포함 + 다음줄 구분선 + 다다음 줄 존재\n",
    "        if (\n",
    "            line.count('|') >= 2 and \n",
    "            any(char in line for char in special_chars) and \n",
    "            i + 2 < len(lines)\n",
    "        ):\n",
    "            next_line = lines[i + 1].strip()\n",
    "            next_next_line = lines[i + 2].strip()\n",
    "\n",
    "            if re.fullmatch(r'\\|?[-| ]+\\|?', next_line):\n",
    "                print(\"컬럼 순서 변경:\", line)\n",
    "\n",
    "                # 잘못된 줄 (| 제거) 먼저 올림\n",
    "                new_lines.append(line.replace('|', '').strip())\n",
    "                # 실제 컬럼명\n",
    "                new_lines.append(next_next_line)\n",
    "                # 구분선\n",
    "                new_lines.append(next_line)\n",
    "\n",
    "                i += 3\n",
    "                continue\n",
    "\n",
    "        # 그 외는 그대로\n",
    "        new_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    return '\\n'.join(new_lines)\n",
    "\n",
    "# llama_docs 각 문서에 적용\n",
    "cleaned_docs = []\n",
    "for doc in llama_docs:\n",
    "    modified = fix_invalid_column_lines(doc.text)\n",
    "    cleaned_docs.append(Document(text=modified))\n",
    "cleaned_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da15ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'(\\|.*?\\|\\n(\\|[-:]+[-|:]*\\|\\n)(\\|.*?\\|\\n)+)', cleaned_docs[13].text, re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0dc7b",
   "metadata": {},
   "source": [
    "### 2) 공백 테이블 전처리 (테이블 병합 및 병합셀 채우기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def merge_pagetext(docs, page_list):\n",
    "    merged_text = \"\"\n",
    "    for page in page_list:\n",
    "        text = docs[page-1].text\n",
    "        merged_text += text\n",
    "    merged_text = merged_text.replace('-----', '') #  페이지 구분 선\n",
    "\n",
    "    # 페이지 넘버 문자열 제거\n",
    "    for page_num in page_list:\n",
    "        merged_text = merged_text.replace(f\"- {page_num}\", '')\n",
    "\n",
    "    return merged_text\n",
    "\n",
    "def is_table_separator(line):\n",
    "    return re.match(r'^\\s*\\|?[:\\-]+(?:\\|[:\\-]+)*\\|?\\s*$', line.strip())\n",
    "\n",
    "def is_table_row(line):\n",
    "    return re.match(r'^\\s*\\|.*\\|\\s*$', line.strip())\n",
    "\n",
    "def is_ignore_line(line):\n",
    "    # 페이지 나눔 같은 구분선: -----, =====, *** 등\n",
    "    return re.match(r'^\\s*[-=*]{3,}\\s*$', line.strip())\n",
    "\n",
    "def extract_combined_tables(text):\n",
    "    lines = text.splitlines()\n",
    "    tables = []\n",
    "    current_table = []\n",
    "    inside_table = False\n",
    "    is_column = False\n",
    "\n",
    "    for line in lines:\n",
    "        if is_table_row(line) or is_table_separator(line):\n",
    "            current_table.append(line.strip())\n",
    "            inside_table = True\n",
    "        elif is_ignore_line(line):\n",
    "            # 페이지 구분 등은 무시하고 표 계속 이어붙임\n",
    "            continue\n",
    "        elif line.strip() == '':\n",
    "            # 빈 줄은 무시 (표 끊지 않음)\n",
    "            continue\n",
    "        else:\n",
    "            # 일반 텍스트: 표 끝으로 간주\n",
    "            if inside_table and current_table:\n",
    "                tables.append('\\n'.join(current_table))\n",
    "                current_table = []\n",
    "                inside_table = False\n",
    "\n",
    "    # 끝에 표가 남아 있다면 추가\n",
    "    if current_table:\n",
    "        tables.append('\\n'.join(current_table))\n",
    "\n",
    "    return tables\n",
    "\n",
    "# 행 수 세는 함수 (헤더 제외, 구분선 제외)\n",
    "def count_rows(md_table):\n",
    "    lines = md_table.strip().splitlines()\n",
    "    return max(0, len(lines) - 2)\n",
    "\n",
    "# 마크다운 테이블 재구성 함수\n",
    "def make_merged_table_md(merged_text):\n",
    "\n",
    "    # 각 줄 단위로 분리\n",
    "    lines = merged_text.strip().split('\\n')\n",
    "\n",
    "    # 첫 번째 컬럼만 헤더 공백값 전처리\n",
    "    lines[0] = lines[0].replace('||', '|Col|')\n",
    "\n",
    "    # 여기서 지우자 잘못 들어간 구분선\n",
    "    \n",
    "\n",
    "    # 결과를 저장할 리스트\n",
    "    merged_table = []\n",
    "    merged_table.extend(lines[:2])\n",
    "    header_found = True\n",
    "    for i in range(2, len(lines)):\n",
    "        line = lines[i]\n",
    "        # print(line)\n",
    "        if '|---|' in line:\n",
    "            merged_table.pop()\n",
    "            line = ''\n",
    "\n",
    "        if line == '':\n",
    "            continue\n",
    "        if re.match(r'^\\|.*\\|$', line.strip()):\n",
    "            # 헤더가 아직 발견되지 않았다면 첫 헤더와 구분선만 추가\n",
    "            if not header_found and re.match(r'^\\|[^|]+\\|[^|]+\\|*', line):\n",
    "                merged_table.append(line)\n",
    "                header_found = True\n",
    "            # 구분선은 무시 (두 번째 이후는)\n",
    "            elif '---' in line:\n",
    "                continue\n",
    "            else:\n",
    "                # 나머지는 데이터 행으로 처리\n",
    "                merged_table.append(line)\n",
    "\n",
    "    # 결과 출력 (마크다운 표 형태)\n",
    "    return '\\n'.join(merged_table)\n",
    "\n",
    "# 마크다운 테이블 재구성 함수\n",
    "def make_merged_table_df(merged_text):\n",
    "    # table_blocks = re.findall(r'(\\|.*?\\|\\n(\\|[-:]+[-|:]*\\|\\n)(\\|.*?\\|\\n)+)', merged_text, re.DOTALL)\n",
    "    # first_block = table_blocks[0]\n",
    "    # table_md = first_block[0]\n",
    "    # rows = table_md.strip().split(\"\\n\")\n",
    "\n",
    "    rows = merged_text.strip().split(\"\\n\")\n",
    "    header = rows[0]  # 컬럼명 (첫 번째 행)\n",
    "    column_list = [col.strip() for col in header.split(\"|\") if col.strip()]\n",
    "    data_rows = rows[2:]\n",
    "\n",
    "    df = pd.read_csv(StringIO(\"\\n\".join([header] + data_rows)), sep=\"|\", engine=\"python\", skipinitialspace=True)\n",
    "    df = df.iloc[:, 1:-1]  # 앞뒤 공백 컬럼 제거\n",
    "    df.columns = column_list \n",
    "    df = df[0:].reset_index(drop=True)  # 데이터만 유지\n",
    "\n",
    "    # ffill은 따로 해주기 (병합셀 심화 과정- 함수 안에서 하거나 반환한 테이블 전처리 따로)\n",
    "    return df\n",
    "\n",
    "table_df_list = []\n",
    "# page_list = [9, 10, 11]\n",
    "for page_list in extended_page_list:\n",
    "    full_text = merge_pagetext(cleaned_docs, page_list)\n",
    "\n",
    "    table_list = extract_combined_tables(full_text)\n",
    "\n",
    "    # 행이 가장 많은 표 하나만 가져오기\n",
    "    max_table = max(table_list, key=count_rows)\n",
    "\n",
    "    # 표 재구성\n",
    "    merged_table_md = make_merged_table_md(max_table)\n",
    "    df = make_merged_table_df(merged_table_md)\n",
    "\n",
    "    target_df = df.ffill(axis=1).ffill(axis=0)\n",
    "    table_df_list.append(target_df)\n",
    "# target_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ccf72",
   "metadata": {},
   "source": [
    "## Azure DI .md 전처리\n",
    "- ■ bullet 예외 데이터 전처리 (제목에 부연 설명 있는 경우, 줄바꿈 안 된 경우 등)\n",
    "- ■ 계층구조 삭제\n",
    "- 공백 테이블 교체 (from PyMuPDF4LLM) -> (개발 중)\n",
    "- html 테이블 -> 텍스트로 설명된 테이블 (from LLM) -> (함수화 및 병합 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown 파일 읽기\n",
    "with open(\"document_result.md\", \"r\", encoding=\"utf-8\") as file:\n",
    "    azure_md = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39c1d5",
   "metadata": {},
   "source": [
    "### 1) ■ bullet 예외 데이터 전처리, 계층구조 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefa3028",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azure_md' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 페이지 분할: 페이지 번호와 내용을 그룹으로 가져오기\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m split_pages = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<!--\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*PageNumber=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m([^\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m]*)\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*-->\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mazure_md\u001b[49m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 불필요한 처음 항목 제거 (페이지 번호 앞 텍스트)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m split_pages \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m split_pages[\u001b[32m0\u001b[39m].strip():\n",
      "\u001b[31mNameError\u001b[39m: name 'azure_md' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 페이지 분할: 페이지 번호와 내용을 그룹으로 가져오기\n",
    "split_pages = re.split(r'<!--\\s*PageNumber=\"([^\"]*)\"\\s*-->', azure_md)\n",
    "\n",
    "# 불필요한 처음 항목 제거 (페이지 번호 앞 텍스트)\n",
    "if split_pages and not split_pages[0].strip():\n",
    "    split_pages = split_pages[1:]\n",
    "\n",
    "# 페이지 목록을 (페이지번호, 내용) 튜플로 묶기\n",
    "page_pairs = list(zip(split_pages[::2], split_pages[1::2]))\n",
    "\n",
    "# 전처리 및 페이지 재조합\n",
    "restructured_pages = []\n",
    "\n",
    "for page_number, content in page_pairs:\n",
    "    lines = content.splitlines()\n",
    "    new_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if \"■\" in line:\n",
    "            # 동작1: '#' 등 마크다운 계층 구조 제거\n",
    "            cleaned_line = re.sub(r'^[#>\\-\\*\\s]+', '', line)\n",
    "            # 동작2: ■ 앞에 공백이 있다면 \\n■ 처리\n",
    "            cleaned_line = re.sub(r'\\s*■', r'\\n■', cleaned_line)\n",
    "            # 동작3: ':'가 있다면 \\n: 처리\n",
    "            cleaned_line = re.sub(r'\\s* :\\s*', r'\\n:', cleaned_line)\n",
    "            # 동작4: \") \" → \")\\n\"\n",
    "            cleaned_line = re.sub(r'\\)\\s+', r')\\n', cleaned_line)\n",
    "            new_lines.append(cleaned_line)\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "\n",
    "    # 전처리된 페이지 내용 조합\n",
    "    modified_content = '\\n'.join(new_lines)\n",
    "    # page_comment = f'<!-- PageNumber=\"{page_number.strip()}\" -->'\n",
    "    restructured_pages.append(f\"{page_number.strip()}\")\n",
    "\n",
    "# 최종 마크다운 문서\n",
    "# final_markdown = '\\n\\n<!-- PageBreak -->\\n\\n'.join(restructured_pages)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n--- Final Markdown ---\\n\")\n",
    "print(restructured_pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64558fb0",
   "metadata": {},
   "source": [
    "### 2) 공백 테이블 교체 (from PyMuPDF4LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bafb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure DI .md에서 연장표 index 찾기 (반례 가능성 有)\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def split_pages(markdown_text):\n",
    "    pattern = r'<!-- PageNumber=\"- (\\d+) -\" -->\\s*<!-- PageBreak -->'\n",
    "    parts = re.split(pattern, markdown_text)\n",
    "    pages = []\n",
    "    for i in range(1, len(parts), 2):\n",
    "        page_num = int(parts[i]) + 1\n",
    "        content = parts[i+1].strip()\n",
    "        pages.append((page_num, content))\n",
    "    return pages\n",
    "\n",
    "def is_table_only(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    text = soup.get_text().strip()\n",
    "    # 태그 중 table 관련 태그만 있는지 확인\n",
    "    allowed_tags = {'table', 'tr', 'td', 'th'}\n",
    "    all_tags = {tag.name for tag in soup.find_all()}\n",
    "    return (text == '') and all_tags.issubset(allowed_tags)\n",
    "\n",
    "def detect_table_transition(pages):\n",
    "    transitions = []\n",
    "    page_unit = []\n",
    "    for i in range(len(pages) - 1):\n",
    "        \n",
    "        curr_page_num, curr_content = pages[i]\n",
    "        next_page_num, next_content = pages[i + 1]\n",
    "\n",
    "        if curr_content.strip().endswith('</table>') and next_content.strip().startswith('<table>'): # 현 페이지가 </table>로 끝나고 다음 페이지가 <table>로 시작할 때\n",
    "            if curr_page_num in page_unit: # 이미 페이지가 page_unit에 있다면\n",
    "                if curr_content.strip().startswith('<table>') and curr_content.strip().endswith('</table>'):\n",
    "                    if len(curr_content.split('</table>')) > 2: # 현재 페이지 안에 표가 2개 이상\n",
    "                        transitions.append(page_unit) # 현재 페이지까지 저장된 unit 저장\n",
    "                        page_unit = []\n",
    "                        page_unit.append(curr_page_num) # 현재 페이지부터 다시 카운트\n",
    "                        page_unit.append(next_page_num)\n",
    "                    else:\n",
    "                        page_unit.append(next_page_num) # 한 페이지 전체가 표. 다음 페이지만 저장\n",
    "                else:\n",
    "                    transitions.append(page_unit)\n",
    "                    page_unit = []\n",
    "                    page_unit.append(curr_page_num)\n",
    "            else:\n",
    "                if page_unit:\n",
    "                    transitions.append(page_unit)\n",
    "                    page_unit = []\n",
    "                page_unit.append(curr_page_num)\n",
    "                page_unit.append(next_page_num)\n",
    "                \n",
    "    transitions.append(page_unit)\n",
    "    return transitions\n",
    "\n",
    "def merge_transitions(transitions, pages_dict):\n",
    "    if not transitions:\n",
    "        return []\n",
    "\n",
    "    merged = []\n",
    "    current_group = transitions[0]\n",
    "\n",
    "    for next_pair in transitions[1:]:\n",
    "        prev_last = current_group[-1]\n",
    "        next_first = next_pair[0]\n",
    "\n",
    "        if prev_last == next_first:\n",
    "            # 중간 페이지가 table-only이면 병합\n",
    "            if is_table_only(pages_dict[prev_last]):\n",
    "                current_group.append(next_pair[1])\n",
    "            else:\n",
    "                merged.append(current_group)\n",
    "                current_group = next_pair\n",
    "        else:\n",
    "            merged.append(current_group)\n",
    "            current_group = next_pair\n",
    "\n",
    "    merged.append(current_group)\n",
    "    return merged\n",
    "\n",
    "def process_markdown_for_table_groups(markdown_text):\n",
    "    pages = split_pages(markdown_text)\n",
    "    pages_dict = dict(pages)\n",
    "    transitions = detect_table_transition(pages)\n",
    "    merged_groups = merge_transitions(transitions, pages_dict)\n",
    "    return merged_groups\n",
    "\n",
    "# with open(\"document_result.md\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     azure_md = file.read()\n",
    "\n",
    "extended_page_list = process_markdown_for_table_groups(azure_md)\n",
    "\n",
    "print(extended_page_list)  # [[3, 4, 5], [7, 8], [10, 11]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표 교체하는 코드 (PyMuPDF4LLM 전처리 과정 이후 사용)\n",
    "# 완성 후 Final Markdown 저장\n",
    "import re\n",
    "\n",
    "# 전처리 및 페이지 재조합\n",
    "pattern = re.compile(r'<table[\\s\\S]*?</table>', re.IGNORECASE)\n",
    "\n",
    "for i in range(len(extended_page_list)):\n",
    "    page_list = extended_page_list[i]\n",
    "    df = table_df_list[i]\n",
    "    new_html_table = df.to_html(index=False, escape=False)\n",
    "\n",
    "    # 첫 페이지\n",
    "    first_page = page_list[0]\n",
    "    page_md = restructured_pages[first_page-1]\n",
    "    matches = list(pattern.finditer(page_md))\n",
    "    matched_table = matches[-1].group()\n",
    "    new_page_md = page_md.replace(matched_table, new_html_table)\n",
    "    restructured_pages[first_page-1] = new_page_md\n",
    "\n",
    "    # 마지막 페이지 + 나머지\n",
    "    for i in range(1, len(page_list)):\n",
    "        page_md = restructured_pages[page_list[i]-1]\n",
    "        matches = list(pattern.finditer(page_md))\n",
    "        matched_table = matches[0].group()\n",
    "        new_page_md = page_md.replace(matched_table, '')\n",
    "        restructured_pages[page_list[i]-1] = new_page_md\n",
    "\n",
    "final_md = '\\n'.join(restructured_pages)\n",
    "\n",
    "with open(\"output.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190d1a3",
   "metadata": {},
   "source": [
    "### 3) html 테이블 -> 텍스트로 설명된 테이블 (from LLM) -> (함수화 및 병합 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94366b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter나 VS Code에서 실행 시 사용할 수 있도록 수정한 버전\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def process_file(input_file_path, output_file_path=None):\n",
    "    \"\"\"\n",
    "    Process an input file through Azure AI to convert HTML tables to text.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    endpoint = os.getenv(\"ENDPOINT_URL\")\n",
    "    deployment = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "    subscription_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "    \n",
    "    if not all([endpoint, deployment, subscription_key]):\n",
    "        raise ValueError(\"환경변수 누락: ENDPOINT_URL, DEPLOYMENT_NAME, AZURE_OPENAI_KEY를 확인하세요.\")\n",
    "    \n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=subscription_key,\n",
    "        api_version=\"2024-05-01-preview\",\n",
    "    )\n",
    "    \n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        input_content = file.read()\n",
    "    \n",
    "    chat_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"너는 HTML 테이블을 읽고 자연스러운 서술형 텍스트로 변환하는 텍스트 변환 엔진이다.\\n\\n입력 데이터는 일반 텍스트와 HTML 코드가 혼합된 문서이며, 이 중 HTML 테이블(`<table>`) 형식으로 작성된 표만을 감지하여 사람이 읽기 쉬운 **자연스러운 텍스트**로 변환하라. 표 외의 일반 텍스트는 **절대로 변경하지 않는다**. \\n\\n출력된 텍스트는 아래의 기준을 모두 따라야 한다:\\n\\n1. 표의 계층 구조, 제목, 셀의 관계를 모두 파악하여 자연어로 기술한다.\\n2. 셀이 병합된 경우 (`rowspan`, `colspan`)에는 의미적으로 내용을 통합하여 풀어서 설명한다.\\n3. 표 안에 또 다른 표가 중첩되어 있는 경우에도 각 표를 계층적으로 처리하고, 문맥상 자연스럽게 연결되도록 한다.\\n4. 빈 칸이 있는 경우, 내용을 유추하지 않고 \\\"(빈칸)\\\" 또는 \\\"해당 없음\\\" 등으로 명확하게 표기한다.\\n5. 항목 간 구분은 \\\"■\\\", \\\"1.\\\", \\\"-\\\" 등을 사용하여 명확히 구분하고, 계층적으로 정리한다.\\n6. 결과 텍스트는 반드시 문맥상 자연스럽고 일관되게 연결되어야 하며, 원래 문서의 흐름과 연결되도록 이어져야 한다.\\n7. HTML 태그가 아닌 일반 텍스트 영역은 절대로 수정하거나 재구성하지 않는다.\\n8. 결과는 마크다운 문서로 사용 가능한 수준의 가독성을 갖춰야 하며, 표를 설명하는 문장은 공식 문서나 계약서 스타일처럼 명료하고 단정하게 작성한다.\\n\\n예외나 애매한 구조가 있어도 최대한 의미를 보존하여 사람이 이해할 수 있도록 직관적으로 설명하라.\\n\\n입력 형식 예시:\\n(본문 텍스트)\\n<table>...</table>\\n(본문 텍스트 계속)\\n\\n출력 형식 예시:\\n(본문 텍스트)\\n■ 항목명  \\n- 내용1  \\n- 내용2  \\n이제 아래에 입력된 문서 내 HTML 테이블을 위 기준에 따라 서술형 텍스트로 변환하라.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": input_content\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=chat_prompt,\n",
    "        max_tokens=1500,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    processed_text = completion.choices[0].message.content\n",
    "    \n",
    "    if not output_file_path:\n",
    "        base, _ = os.path.splitext(input_file_path)\n",
    "        output_file_path = f\"{base}_processed.txt\"\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(processed_text)\n",
    "    \n",
    "    print(f\"✅ 변환 완료: {output_file_path}\")\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "#=======================================================================\n",
    "\n",
    "# 🔽 여기서 input/output 경로 지정해서 실행\n",
    "input_path = \"document_result.md\"  # ← 실제 파일 경로로 수정\n",
    "output_path = \"result.txt\"  # 또는 \"결과저장파일.txt\"\n",
    "\n",
    "process_file(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
